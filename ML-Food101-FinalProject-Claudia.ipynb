{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RG-lsZVmRqQc"
   },
   "source": [
    "Author: Claudia Gusti\n",
    "Date: 12/3/22\n",
    "\n",
    "Approaches to Multi Class Food Image Classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MewDGtijR3W2"
   },
   "source": [
    "# Download and extract Food 101 dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Making sure we have the right imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pDYoVw1dqL-c"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "#Necessay tensorflow imports\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.callbacks import TensorBoard, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications import VGG16, VGG19\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "# For image processing, visualizing images and plotting graphs\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "\n",
    "from shutil import copy\n",
    "from shutil import copytree, rmtree\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure GPU has enough space\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "gpu_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "rtY17-eAswy3",
    "outputId": "2423150f-296c-431a-fcb3-8f040c5f6829"
   },
   "outputs": [],
   "source": [
    "# Check TF version and whether GPU is enabled\n",
    "print(tf.__version__)\n",
    "print(tf.test.gpu_device_name())\n",
    "\n",
    "'''Expected output: \n",
    "2.2.0\n",
    "/device:GPU:0'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w8woIcFbuTFR"
   },
   "source": [
    "Next, let's download and extract [Food-101](https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5LthVX7Ps0MT"
   },
   "outputs": [],
   "source": [
    "# Helper function to download and extract data and extract\n",
    "\n",
    "def get_data():\n",
    "  if \"food-101\" in os.listdir():\n",
    "    print(\"Dataset already exists\")\n",
    "  else:\n",
    "    tf.keras.utils.get_file(\n",
    "    'food-101.tar.gz',\n",
    "    'http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz',\n",
    "    cache_subdir='./content/',\n",
    "    extract=True,\n",
    "    archive_format='tar',\n",
    "    cache_dir=None\n",
    "    )\n",
    "    print(\"Dataset downloaded and extracted successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "75Kafq7-vB48",
    "outputId": "7258c69d-3bae-4316-8353-3e831de407fc"
   },
   "outputs": [],
   "source": [
    "# Call the helper function\n",
    "get_data() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4sI3z8O3na1Q"
   },
   "source": [
    "# Analysing data and visualizing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "F2bNGyxPShAQ",
    "outputId": "1e75b105-9e03-4315-9f5c-1612030ee463"
   },
   "outputs": [],
   "source": [
    "#Lets have a look into the directory\n",
    "os.listdir('../.keras/content/food-101/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6m9uFjqQWwcp"
   },
   "source": [
    "This dataset has 101 different classes of food with 1000 images for each class.\n",
    "This 1000 images are divided into 750 training samples and 250 test samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwOCkJC-Wklv"
   },
   "source": [
    "Next we list all the classes/labels of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "H9Ygi-_-4cxP",
    "outputId": "72f6b5fd-28a7-4f0e-f065-7a545248f6ee"
   },
   "outputs": [],
   "source": [
    "#List of all classes\n",
    "foods_sorted = sorted(os.listdir('../.keras/content/food-101/images'))\n",
    "foods_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "id": "UdeYd5QT-you",
    "outputId": "ed00abe6-f13b-4b3e-d009-559f31270343"
   },
   "outputs": [],
   "source": [
    "#The meta file contains labels for train and test in txt format as well 101 classes\n",
    "os.listdir('../.keras/content/food-101/meta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5pb-4SqmUPK"
   },
   "source": [
    "Now let's visualize a randomly selected image from every class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 908
    },
    "id": "3GxBqcd0-4LL",
    "outputId": "004f3033-01b4-47e3-d5bf-69ec2ca3841b"
   },
   "outputs": [],
   "source": [
    "# Visualize the data, showing one image per class from 101 classes\n",
    "rows = 17\n",
    "cols = 6\n",
    "fig, ax = plt.subplots(rows, cols, figsize=(50,50))\n",
    "fig.suptitle(\"Showing one random image from each class\", y=1.05, fontsize=60)\n",
    "data_dir = \"../.keras/content/food-101/images\"\n",
    "foods_sorted = sorted(os.listdir(data_dir))\n",
    "food_id = 0\n",
    "for i in range(rows):\n",
    "  for j in range(cols):\n",
    "    try:\n",
    "      food_selected = foods_sorted[food_id] \n",
    "      food_id += 1\n",
    "    except:\n",
    "      break\n",
    "    food_selected_images = os.listdir(os.path.join(data_dir,food_selected)) # returns the list of all files present in each food category\n",
    "    food_selected_random = np.random.choice(food_selected_images) # picks one food item from the list as choice, takes a list and returns one random item\n",
    "    img = plt.imread(os.path.join(data_dir,food_selected, food_selected_random))\n",
    "    ax[i][j].imshow(img)\n",
    "    ax[i][j].set_title(food_selected, pad = 20,fontsize=40)\n",
    "    \n",
    "plt.setp(ax, xticks=[],yticks=[])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ij3Hzw5e2FNO"
   },
   "source": [
    "# Splitting the data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7fokfk9EFBXT"
   },
   "outputs": [],
   "source": [
    "# Helper method to split dataset into train and test folders\n",
    "from shutil import copy\n",
    "def prepare_data(filepath, src, dest):\n",
    "  classes_images = defaultdict(list)\n",
    "  with open(filepath, 'r') as txt:\n",
    "      paths = [read.strip() for read in txt.readlines()]\n",
    "      for p in paths:\n",
    "        food = p.split('/')\n",
    "        classes_images[food[0]].append(food[1] + '.jpg')\n",
    "\n",
    "  for food in classes_images.keys():\n",
    "    print(\"\\nCopying images into \",food)\n",
    "    if not os.path.exists(os.path.join(dest,food)):\n",
    "      os.makedirs(os.path.join(dest,food))\n",
    "    for i in classes_images[food]:\n",
    "      copy(os.path.join(src,food,i), os.path.join(dest,food,i))\n",
    "  print(\"Copying Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7t8zAtXr2Mm1",
    "outputId": "6565141d-d21f-49f2-fc7b-fd0ecb5b0112"
   },
   "outputs": [],
   "source": [
    "# Prepare train dataset by copying images from food-101/images to food-101/train using the file train.txt\n",
    "print(\"Creating train data...\")\n",
    "prepare_data('../.keras/content/food-101/meta/train.txt', '../.keras/content/food-101/images', '../.keras/content/food-101/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-o5b9h_72Tog",
    "outputId": "cb26a2d0-430c-456d-a110-320641206af3"
   },
   "outputs": [],
   "source": [
    "# Prepare test data by copying images from food-101/images to food-101/test using the file test.txt\n",
    "print(\"Creating test data...\")\n",
    "prepare_data('../.keras/content/food-101/meta/test.txt', '../.keras/content/food-101/images', '../.keras/content/food-101/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7bG-UMZG8Kw4"
   },
   "source": [
    "# Create a subset of data to test some SOTA models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4QSM7Z28e8s"
   },
   "source": [
    "\n",
    "\n",
    "*   Experimenting different architectures on the complete dataset would take a lot of time and computation power. \n",
    "*   So instead we create a subset of 4 classes and test a couple of architectures for evaluting the performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0P-o1_MX2UG8"
   },
   "outputs": [],
   "source": [
    "# Helper method to create train_mini and test_mini data samples\n",
    "from shutil import copytree, rmtree\n",
    "def dataset_mini(food_list, src, dest):\n",
    "  if not os.path.exists(dest):\n",
    "    os.makedirs(dest)   #Make a directory if it does not exists\n",
    "  for food_item in food_list :\n",
    "    print(\"Copying images into\",food_item)\n",
    "    copytree(os.path.join(src,food_item), os.path.join(dest,food_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JfpcvcBe_LyK"
   },
   "outputs": [],
   "source": [
    "# picking 4 random food items and generating separate data folders for the same\n",
    "food_list = ['apple_pie','cannoli','dumplings', 'miso_soup']  #You can choose any food items\n",
    "src_train = '../.keras/content/food-101/train'\n",
    "dest_train = '../.keras/content/food-101/train_mini'\n",
    "src_test = '../.keras/content/food-101/test'\n",
    "dest_test = '../.keras/content/food-101/test_mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0QeYcue1_mnl",
    "outputId": "15a22171-894e-41d2-aa5c-87e2dc5e0ae6"
   },
   "outputs": [],
   "source": [
    "#Create subset for training data \n",
    "print(\"Creating train data folder with new classes\")\n",
    "dataset_mini(food_list, src_train, dest_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VSzw3K6W_uSX",
    "outputId": "fc3b1530-599f-496a-96a3-fd9854d3f6c8"
   },
   "outputs": [],
   "source": [
    "#Create subset for test data\n",
    "print(\"Creating test data folder with new classes\")\n",
    "dataset_mini(food_list, src_test, dest_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G7Sm66PBAH0i"
   },
   "source": [
    "All the below models have been referred from  [table](https://keras.io/api/applications/) to get an insight for Top-1 and Top-5 accuracy of various SOTA models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTHNYwaEImF7"
   },
   "source": [
    "# Testing some State-Of-The-Art model on mini dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b9fU03P_EfKU"
   },
   "source": [
    "## Testing VGG16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KuJpJHftEjmB"
   },
   "outputs": [],
   "source": [
    "# Declare some variables\n",
    "\n",
    "n_classes = 4   #num of output classes\n",
    "img_width, img_height = 224, 224   #Default image size for VGG16 model\n",
    "train_data_dir = '../.keras/content/food-101/train_mini'\n",
    "validation_data_dir = '../.keras/content/food-101/test_mini'\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BqUKZ08DEee2",
    "outputId": "1d42eba4-47ec-4d26-8ac3-d1630f97c21a"
   },
   "outputs": [],
   "source": [
    "# Perform data augmentation using Image data generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')  #Since it's a multiclass classification so class_mode = 'categorical'\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L-HXE90fEwCM",
    "outputId": "5498a46b-c5dd-4818-f1e2-d1399c7cf497",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "VGG16 = VGG16(weights='imagenet', include_top=False)\n",
    "x = VGG16.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128,activation='relu')(x)\n",
    "x = Dropout(0.2)(x)    #Dropout to prevent overfitting\n",
    "\n",
    "                              #L2 regularization to prevent overfitting\n",
    "predictions = Dense(n_classes ,kernel_regularizer=regularizers.l2(0.005), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=VGG16.input, outputs=predictions)\n",
    "\n",
    "#Compile the model            #Learning rate = 0.001\n",
    "model.compile(optimizer=SGD(lr=0.001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#fit the model\n",
    "history_VGG16 = model.fit_generator(train_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    epochs=10,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3AxpJ1W31x9"
   },
   "source": [
    "## Testing InceptionV3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "js7RWBa5_9Yd"
   },
   "outputs": [],
   "source": [
    "# Declare some variables\n",
    "\n",
    "n_classes = 4   #num of output classes\n",
    "img_width, img_height = 299, 299   #Default image size for Inception and Xception model\n",
    "train_data_dir = '../.keras/content/food-101/train_mini'\n",
    "validation_data_dir = '../.keras/content/food-101/test_mini'\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C15UUiR6GL2G",
    "outputId": "10d34c96-e091-47d8-fe72-b7ce04de79d3"
   },
   "outputs": [],
   "source": [
    "# Perform data augmentation using Image data generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')  #Since it's a multiclass classification so class_mode = 'categorical'\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1aUp5xaKGf__",
    "outputId": "3ae51422-d3f8-48ce-b159-5a0671fd960f"
   },
   "outputs": [],
   "source": [
    "inception = InceptionV3(weights='imagenet', include_top=False)\n",
    "#add a global spatial average pooling layer\n",
    "x = inception.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "#add a fully connected layer\n",
    "x = Dense(128,activation='relu')(x)\n",
    "x = Dropout(0.2)(x)    #Dropout to prevent overfitting\n",
    "\n",
    "\n",
    "#add a logistic layer - this is the output layer that will predict n number of class \n",
    "#L2 regularization to prevent overfitting\n",
    "predictions = Dense(n_classes ,kernel_regularizer=regularizers.l2(0.005), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inception.input, outputs=predictions)\n",
    "\n",
    "#Compile the model            #Learning rate = 0.001\n",
    "model.compile(optimizer=SGD(lr=0.001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#fit the model\n",
    "history_inception = model.fit_generator(train_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    epochs=10,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2b_rMdqILPk4"
   },
   "source": [
    "## Testing Xception model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XFhOtAE_LGlU",
    "outputId": "ad69c8c1-4ae9-4ff7-cb44-aa92ae0ffc92"
   },
   "outputs": [],
   "source": [
    "xception = Xception(weights='imagenet', include_top=False)\n",
    "x = xception.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128,activation='relu')(x)\n",
    "x = Dropout(0.2)(x)    #Dropout to prevent overfitting\n",
    "\n",
    "                           #L2 regularization to prevent overfitting \n",
    "predictions = Dense(n_classes ,kernel_regularizer=regularizers.l2(0.005), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=xception.input, outputs=predictions)\n",
    "\n",
    "#Compile the model     #Learning rate = 0.001\n",
    "model.compile(optimizer=SGD(lr=0.001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "history_xception = model.fit_generator(train_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    epochs=10,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PuztlBaNn2fQ"
   },
   "source": [
    "# Plotting the results for all the 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "fseoTLJEn0hY",
    "outputId": "aa42fd93-a579-4d3a-c05e-93c9b6357406"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#Function to plot Accuracy\n",
    "def plot_accuracy(title):\n",
    "    plt.title(title)\n",
    "    plt.plot(history_inception.history['val_accuracy'])\n",
    "    plt.plot(history_xception.history['val_accuracy'])\n",
    "    plt.plot(history_VGG16.history['val_accuracy'])\n",
    "    plt.ylabel('Validation accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['InceptionV3', 'Xception', 'VGG16'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "#Function to plot Loss\n",
    "def plot_loss(title):\n",
    "    plt.title(title)\n",
    "    plt.plot(history_inception.history['val_loss'])\n",
    "    plt.plot(history_xception.history['val_loss'])\n",
    "    plt.plot(history_VGG16.history['val_loss'])\n",
    "    plt.ylabel('Validation Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['InceptionV3', 'Xception', 'VGG16'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_accuracy('Accuracy comparison of Models')\n",
    "plot_loss('Loss comparison of Models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLNDD0Yow3am"
   },
   "source": [
    "##Having a closer look on accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "xHZiZqFTwP3t",
    "outputId": "ac7aa086-b589-4e60-e496-b898d9d15876"
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(history_inception.history['val_accuracy'][4:])\n",
    "plt.plot(history_xception.history['val_accuracy'][4:])\n",
    "plt.plot(history_VGG16.history['val_accuracy'][4:])\n",
    "plt.ylabel('Validation accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['InceptionV3', 'Xception', 'VGG16'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "5kLnEwHsxqoC",
    "outputId": "cfd6b602-4580-4ba1-d6a6-40a952e588ff"
   },
   "outputs": [],
   "source": [
    "plt.plot(history_inception.history['val_loss'][4:])\n",
    "plt.plot(history_xception.history['val_loss'][4:])\n",
    "plt.plot(history_VGG16.history['val_loss'][4:])\n",
    "plt.ylabel('Validation accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['InceptionV3', 'Xception', 'ResNet50'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkwxFCFuyv8w"
   },
   "source": [
    "From the above analysis, Inception modelV3 gives better convergence as compared to Inception and ResNet50 for Food-101 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning InceptionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0AYwSoWibqjF"
   },
   "source": [
    "#Fine tuning process for InceptionV3 model all 101 classes\n",
    " \n",
    "Fine tuning methodology: \n",
    "1. Freezing all layers learning a classifier on top of it - similar to transfer learning (and using data augmentation)\n",
    "2. Training the last 3 convolutional layers (with data augmentation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rK_r34Y_xzOx"
   },
   "outputs": [],
   "source": [
    "# Declare some constants\n",
    "\n",
    "n_classes = 101   # total num of output classes\n",
    "img_width, img_height = 299, 299   #Default image size for InceptionV3 model\n",
    "batch_size = 32\n",
    "\n",
    "train_data_dir = '../.keras/content/food-101/train'   #Directory for train dataset\n",
    "validation_data_dir = '../.keras/content/food-101/test'     #Directory for test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-ROH7K03KyY"
   },
   "source": [
    "Now we use [Image Data Generator](https://keras.io/api/preprocessing/image/) for performing data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PTw5xLO93JH_",
    "outputId": "93c7806d-01b2-4340-cf5f-9fb8c2bab89b"
   },
   "outputs": [],
   "source": [
    "# Perform advance data augmentation using Image data generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    rotation_range = 40,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')  #Since it's a multiclass classification so class_mode = 'categorical'\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pYaWGi6_6MTh"
   },
   "source": [
    "##Loading InceptionV3 model\n",
    "\n",
    "Let's load the InceptionV3 model and attach Fully connected layers on top of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l7k8L35Q6Ahy",
    "outputId": "a88d193c-11c2-47e6-ac37-552cafb06e02",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inceptionV3 = InceptionV3(weights='imagenet', include_top=False, input_shape=(299,299,3))\n",
    "x = inceptionV3.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "#I have just used 128 hidden units due to restricted Colab GPU runtime. \n",
    "#For such huge dataset, 1024 or 512 hidden units should be ideally preferred.\n",
    "x = Dense(128,activation='relu')(x)  \n",
    "x = Dropout(0.4)(x)    #Dropout to prevent overfitting\n",
    "\n",
    "#Freeze all the layers of the xception model\n",
    "for layer in inceptionV3.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "                           #L2 regularization to prevent overfitting \n",
    "predictions = Dense(n_classes ,kernel_regularizer=regularizers.l2(0.0001), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inceptionV3.input, outputs=predictions)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_hyz2D_8f2G"
   },
   "source": [
    "##Compile the model and define custom callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WO6hcr8p7SQW",
    "outputId": "35ad7710-d694-41b6-be00-f849ed5ce7b7"
   },
   "outputs": [],
   "source": [
    "#Compile the model            #Learning rate = 0.001\n",
    "model.compile(optimizer=SGD(lr=0.001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Callback for model saving and reducing learning rate on plateau\n",
    "callbacks_list = [callbacks.ModelCheckpoint(\n",
    "        filepath = './InceptionV3-model.h5',\n",
    "        monitor = 'val_loss',\n",
    "        save_best_only = True),\n",
    "        callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.1,\n",
    "            patience=2,\n",
    "            mode='min',\n",
    "            min_lr=1e-8)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "id": "eNgpC3p58axp",
    "outputId": "a1185604-ef0c-480a-cb3e-24df691b4d53"
   },
   "outputs": [],
   "source": [
    "#Fit the model\n",
    "history = model.fit_generator(train_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility function for plotting of the model results\n",
    "def visualize_results(history):\n",
    "    # Plot the accuracy and loss curves\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    " \n",
    "    epochs = range(len(acc))\n",
    " \n",
    "    plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    " \n",
    "    plt.figure()\n",
    " \n",
    "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    " \n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_results(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utility function for obtaining errors\n",
    "\n",
    "def obtain_errors(val_generator, predictions):\n",
    "    # Get the filenames from the generator\n",
    "    fnames = validation_generator.filenames\n",
    " \n",
    "    # Get the ground truth from generator\n",
    "    ground_truth = validation_generator.classes\n",
    " \n",
    "    # Get the dictionary of classes\n",
    "    label2index = validation_generator.class_indices\n",
    " \n",
    "    # Obtain the list of the classes\n",
    "    idx2label = list(label2index.keys())\n",
    "    print(\"The list of classes: \", idx2label)\n",
    " \n",
    "    # Get the class index\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    " \n",
    "    errors = np.where(predicted_classes != ground_truth)[0]\n",
    "    print(\"Number of errors = {}/{}\".format(len(errors),validation_generator.samples))\n",
    "     \n",
    "    return idx2label, errors, fnames\n",
    " \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_errors(idx2label, errors, predictions, fnames):\n",
    "    # Show the errors\n",
    "    for i in range(len(errors)):\n",
    "        pred_class = np.argmax(predictions[errors[i]])\n",
    "        pred_label = idx2label[pred_class]\n",
    " \n",
    "        title = 'Original label:{}, Prediction :{}, confidence : {:.3f}'.format(\n",
    "            fnames[errors[i]].split('/')[0],\n",
    "            pred_label,\n",
    "            predictions[errors[i]][pred_class])\n",
    " \n",
    "        original = load_img('{}/{}'.format(validation_data_dir,fnames[errors[i]]))\n",
    "        plt.figure(figsize=[7,7])\n",
    "        plt.axis('off')\n",
    "        plt.title(title)\n",
    "        plt.imshow(original)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline for error analysis\n",
    "\n",
    "# example of loading an image with the Keras API\n",
    "from keras.preprocessing.image import load_img\n",
    "\n",
    "\n",
    "predictions = model.predict(validation_generator, steps=validation_generator.samples/validation_generator.batch_size,verbose=1)\n",
    " \n",
    "# Run the function to get the list of classes and errors\n",
    "idx2label, errors, fnames = obtain_errors(validation_generator, predictions)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function to illustrate the error cases\n",
    "show_errors(idx2label, errors, predictions, fnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HwjP-QUWW-nu"
   },
   "source": [
    "## Training the last convolutional networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JrNwpF2g8PNI"
   },
   "source": [
    "Let's try to fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lets choose the layers which are updated by training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CCqgtbRw8N8y"
   },
   "outputs": [],
   "source": [
    "# Freeze layers till \n",
    "for layer in model.layers[:279]:\n",
    "  layer.trainable =  False\n",
    "\n",
    "#Train weights from \n",
    "for layer in model.layers[279:]:\n",
    "  layer.trainable = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "orzojZEg8yY3"
   },
   "outputs": [],
   "source": [
    "#Compile the model            #Learning rate = 0.0001\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Callback for model saving and reducing learning rate on plateau\n",
    "callbacks_list = [callbacks.ModelCheckpoint(\n",
    "        filepath = './InceptionV3-model.h5',\n",
    "        monitor = 'val_accuracy',\n",
    "        save_best_only = True),\n",
    "        callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_accuracy',\n",
    "            factor=0.1,\n",
    "            patience=2,\n",
    "            mode='max',\n",
    "            min_delta=0.002,\n",
    "            min_lr=1e-8),\n",
    "        callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy', min_delta=0.001, patience=3, verbose=1, mode='max',\n",
    "    baseline=None)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "6InYmgAM9PBB",
    "outputId": "f5d88002-e81d-47fc-a956-4f8de6399d5d"
   },
   "outputs": [],
   "source": [
    "#Fit the model\n",
    "history = model.fit_generator(train_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(history):\n",
    "    # Plot the accuracy and loss curves\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    " \n",
    "    epochs = range(len(acc))\n",
    " \n",
    "    plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    " \n",
    "    plt.figure()\n",
    " \n",
    "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    " \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(validation_generator, steps=validation_generator.samples/validation_generator.batch_size,verbose=1)\n",
    " \n",
    "# Run the function to get the list of classes and errors\n",
    "idx2label, errors, fnames = obtain_errors(validation_generator, predictions)\n",
    " \n",
    "# Run the function to illustrate the error cases\n",
    "show_errors(idx2label, errors, predictions, fnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VjHJ0QiyGKWD"
   },
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "O0tO8zsCakwN",
    "outputId": "c56d9471-a4e4-43e3-fbb7-b49a0ecb0090"
   },
   "outputs": [],
   "source": [
    "model.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OY9gmhjj3_W_"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "MewDGtijR3W2",
    "4sI3z8O3na1Q",
    "Ij3Hzw5e2FNO",
    "7bG-UMZG8Kw4",
    "b9fU03P_EfKU",
    "w3AxpJ1W31x9",
    "2b_rMdqILPk4",
    "PuztlBaNn2fQ",
    "xLNDD0Yow3am",
    "x8FCV0FM2f2V",
    "pYaWGi6_6MTh",
    "2_hyz2D_8f2G",
    "m062szV3cWHr"
   ],
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
